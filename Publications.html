<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/">

<link rel="stylesheet" href="./Botao_files/jemdoc.css" type="text/css">
<title>Publications </title>
</head>
<body data-new-gr-c-s-check-loaded="14.1080.0" data-gr-ext-installed="">
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html" >About&nbsp;me</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>

</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications </h1>
</div>
<ul>
<h2>2022 </h2>

  <li><p> 
  <strong>Regret Bounds for Information-Directed Reinforcement Learning</strong><br>
  <b>Botao Hao</b>, Tor Lattimore <br>
  <em>NeurIPS 2022. </em> [<a href="https://arxiv.org/abs/2206.04640">arXiv</a>]
  </p></li>	
  
  <li><p> 
  <strong>The Neural Testbed: Evaluating Predictive Distributions</strong><br>
 Ian Osband, Zheng Wen, Seyed Mohammad Asghari, Vikranth Dwaracherla, <b>Botao Hao</b>, Morteza Ibrahimi, Dieterich Lawson, Xiuyuan Lu, Brendan O'Donoghue, Benjamin Van Roy <br>
  <em>NeurIPS 2022. </em> [<a href="https://arxiv.org/abs/2110.04629">arXiv</a>]
  </p></li>

  <li><p> 
  <strong> Interacting Contour Stochastic Gradient Langevin Dynamics</strong><br>
  Wei Deng, Siqi Liang, <b>Botao Hao</b>, Guang Lin, Faming Liang <br>
  <em>ICML 2022. </em> [<a href="https://arxiv.org/abs/2202.09867">arXiv</a>]
  </p></li>	
  
  <li><p> 
  <strong>Contextual Information-Directed Sampling</strong><br>
  <b>Botao Hao</b>, Tor Lattimore, Chao Qin <br>
  <em>ICML 2022. </em> [<a href="https://arxiv.org/abs/2205.10895">arXiv</a>]
  </p></li>
	
  <li><p> 
  <strong>Confident Least Square Value Iteration with Local Access to a Simulator</strong><br>
  <b>Botao Hao</b>, Nevena Lazic, Dong Yin, Yasin Abbasi-Yadkori, Csaba Szepesvári<br>
  <em>AISTATS 2022. </em> [<a href="https://proceedings.mlr.press/v151/hao22a.html">Proceedings</a>]
  </p></li>	

  <li><p> 
  <strong>Efficient Local Planning with Linear Function Approximation</strong><br>
  Dong Yin, <b>Botao Hao</b>, Yasin Abbasi-Yadkori, Nevena Lazic, Csaba Szepesvári<br>
  <em>ALT 2022. </em> [<a href="https://arxiv.org/abs/2108.05533">arXiv</a>]
  </p></li>	
  
  

<h2>2021 </h2>

  <li><p> 
  <strong>Information Directed Sampling for Sparse Linear Bandits</strong><br>
  <b>Botao Hao</b>, Tor Lattimore, Wei Deng <br>
  <em>NeurIPS 2021 <strong style="color: red;">(spotlight)</strong>.
   </em>
  [<a href="https://proceedings.neurips.cc/paper/2021/hash/8ba6c657b03fc7c8dd4dff8e45defcd2-Abstract.html">Proceedings</a>]
  [<a href="NeurIPS2021_Sparse_IDS_slides.pdf">slides</a>]
  </p></li>

  <li><p> 
  <strong>Bandit Phase Retrieval</strong><br>
  Tor Lattimore, <b>Botao Hao</b><br>
  <em>NeurIPS 2021. </em>
  [<a href="https://arxiv.org/abs/2106.01660">arXiv</a>]
  </p></li>


  <li><p> 
  <strong>Bootstrapping Fitted Q-Evaluation for Off-Policy Inference</strong><br>
  <b>Botao Hao</b>, Xiang Ji, Yaqi Duan, Hao Lu, Csaba Szepesvári, Mengdi Wang <br>
  <em>ICML 2021. </em>
  [<a href="https://arxiv.org/abs/2102.03607">arXiv</a>]
  </p></li>

  <li><p> 
  <strong>Sparse Feature Selection Makes Batch Reinforcement Learning
  More Sample Efficient</strong><br>
  <b>Botao Hao</b>, Yaqi Duan, Tor Lattimore, Csaba Szepesvári, Mengdi Wang <br>
  <em>ICML 2021. </em>
  [<a href="https://arxiv.org/abs/2011.04019">arXiv</a>]
  </p></li>


  <li><p> 
  <strong>Online Sparse Reinforcement Learning</strong><br>
  <b>Botao Hao</b>, Tor Lattimore, Csaba Szepesvári, Mengdi Wang <br>
  <em>AISTATS 2021. </em>
  [<a href="https://arxiv.org/pdf/2011.04018.pdf">arXiv</a>]
  [<a href="AISTATS2021_SparseRL_Poster.pdf">poster</a>]
  </p></li>


  <li><p> 
  <strong>Adaptive Approximate Policy Iteration</strong><br>
  <b>Botao Hao</b>, Nevena Lazic, Yasin Abbasi-Yadkori, Pooria Joulani, Csaba Szepesvári<br>
  <em>AISTATS 2021. </em>
  [<a href="https://arxiv.org/pdf/2002.03069.pdf">arXiv</a>]
  [<a href="AISTATS2021_AAPI_Poster.pdf">poster</a>]
  </p></li>

  <li><p> 
  <strong>Sparse Tensor Additive Regression</strong><br>
  <b>Botao Hao</b>, Boxiang Wang, Pengyuan Wang, Jingfei Zhang, Jian Yang, Will Wei Sun<br>
  <em>Journal of Machine Learning Research. </em>
  [<a href="https://arxiv.org/abs/1904.00479">arXiv</a>]
  </p></li>
	

<h2>2020 </h2>

  <li><p> 
  <strong>High-Dimensional Sparse Linear Bandits</strong><br>
  <b>Botao Hao</b>, Tor Lattimore,  Mengdi Wang<br>
  <em>NeurIPS 2020. </em>
  [<a href="https://arxiv.org/pdf/2011.04020.pdf">arXiv</a>]
  [<a href="NeurIPS2020_HD_Bandits_Slides.pdf">slides</a>]
  [<a href="NeurIPS2020_HD_Bandits_Poster.pdf">poster</a>]
  </p></li>



  <li><p> 
  <strong>Adaptive Exploration in Linear Contextual Bandit</strong><br>
  <b>Botao Hao</b>, Tor Lattimore,  Csaba Szepesvári<br>
  <em>AISTATS 2020. </em>
  [<a href="https://arxiv.org/abs/1910.06996">arXiv</a>]
  [<a href="adaptive_exploration.pdf">slides</a>]
  </p></li>
  
  <li><p> 
  <strong>Sparse and Low-rank Tensor Estimation via Cubic Sketchings</strong><br>
  <b>Botao Hao</b>, Anru Zhang, Guang Cheng<br>
  <em>IEEE Transactions on Information Theory </em>
  [<a href="https://arxiv.org/abs/1801.09326">arXiv</a>]
  [<a href="fbdc.pdf">slides</a>]
  <br>
  <em>Accepted in part to AISTATS 2020.</em>
  </p></li>
  
  
<h2>2019 </h2>

  <li><p> 
  <strong>Bootstrapping Upper Confidence Bound</strong><br>
  <b>Botao Hao</b>, Yasin Abbasi-Yadkori, Zheng Wen, Guang Cheng<br>
  <em>NeurIPS 2019. </em>
  [<a href="https://arxiv.org/abs/1906.05247">arXiv</a>]
  [<a href="poster_nips.pdf">poster</a>]
  </p></li>

  <li><p> 
  <strong>Nonparametric Bayesian Aggregation for Massive Data</strong><br>
	Zuofeng Shang, <strong>Botao Hao, </strong> Guang Cheng <br />
  <em>Journal of Machine Learning Research. </em>
   [<a href="http://www.jmlr.org/papers/v20/17-641.html">pdf</a>]

<h2>2018 </h2>
  <li><p> 
  <strong>Simultaneous Clustering and Estimation of Heterogeneous Graphical Models</strong><br>
  <b>Botao Hao</b>, Will Wei Sun, Yufeng Liu, Guang Cheng<br>
  <em>Journal of Machine Learning Research. </em>
  [<a href="http://www.jmlr.org/papers/v18/17-019.html">pdf</a>]
  [<a href="SLDS_talk.pdf">slides</a>]
  </p></li>
	 
	  

 
	
 






 

  
</ul>
</td>
</tr>
</tbody></table>


</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>