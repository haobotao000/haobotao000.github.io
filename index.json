[{"authors":["admin"],"categories":null,"content":"I am currently a fifth year Ph.D. student at Department of Statistics, Purdue Unversity. My advisor is Prof. Guang Cheng.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am currently a fifth year Ph.D. student at Department of Statistics, Purdue Unversity. My advisor is Prof. Guang Cheng.","tags":null,"title":"Botao Hao","type":"author"},{"authors":["**Botao Hao**","Yasin Abbasi-Yadkori","Zheng Wen","Guang Cheng"],"categories":null,"content":"","date":1560283083,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560283083,"objectID":"fc6f645f2f918d08f319fc5c7a000cf9","permalink":"/publication/bucb/","publishdate":"2019-06-11T20:58:03+01:00","relpermalink":"/publication/bucb/","section":"publication","summary":"Upper Confidence Bound (UCB) method is arguably the most celebrated one used in online decision making with partial information feedback. Existing techniques for constructing confidence bounds are typically built upon various concentration inequalities, which thus lead to over-exploration. In this paper, we propose a non-parametric and data-dependent UCB algorithm based on the multiplier bootstrap. To improve its finite sample performance, we further incorporate second-order correction into the above construction. In theory, we derive both problem-dependent and problem-independent regret bounds for multi-armed bandits under a much weaker tail assumption than the standard sub-Gaussianity. Numerical results demonstrate significant regret reductions by our method, in comparison with several baselines in a range of multi-armed and linear bandit problems. ","tags":[],"title":"Bootstrapping Upper Confidence Bound","type":"publication"},{"authors":["**Botao Hao**","Boxiang Wang","Pengyuan Wang","Jingfei Zhang","Jian Yang","Will Wei Sun"],"categories":null,"content":"","date":1554082015,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554082015,"objectID":"fc14b480dad03f78672eb320df23d311","permalink":"/publication/star/","publishdate":"2019-03-31T21:26:55-04:00","relpermalink":"/publication/star/","section":"publication","summary":"Tensors are becoming prevalent in modern applications such as medical imaging and digital marketing. In this paper, we propose a sparse tensor additive regression (STAR) that models a scalar response as a flexible nonparametric function of tensor covariates. The proposed model effectively exploits the sparse and low-rank structures in the tensor additive regression. We formulate the parameter estimation as a non-convex optimization problem, and propose an efficient penalized alternating minimization algorithm. We establish a non-asymptotic error bound for the estimator obtained from each iteration of the proposed algorithm, which reveals an interplay between the optimization error and the statistical rate of convergence. We demonstrate the efficacy of STAR through extensive comparative simulation studies, and an application to the click-through-rate prediction in online advertising.","tags":[],"title":"Sparse Tensor Additive Regression","type":"publication"},{"authors":[" **Botao Hao**","Anru Zhang","Guang Cheng"],"categories":null,"content":"","date":1522543991,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522543991,"objectID":"da2cd2032a54d6a8bdd4dfea9c797d45","permalink":"/publication/tensor/","publishdate":"2018-03-31T20:53:11-04:00","relpermalink":"/publication/tensor/","section":"publication","summary":"In this paper, we propose a general framework for sparse and low-rank tensor estimation from cubic sketchings. A two-stage non-convex implementation is developed based on sparse tensor decomposition and thresholded gradient descent, which ensures exact recovery in the noiseless case and stable recovery in the noisy case with high probability. The non-asymptotic analysis sheds light on an interplay between optimization error and statistical error. The proposed procedure is shown to be rate-optimal under certain conditions. As a technical by-product, novel high-order concentration inequalities are derived for studying high-moment sub-Gaussian tensors. An interesting tensor formulation illustrates the potential application to high-order interaction pursuit in high-dimensional linear regression.","tags":[],"title":"Sparse and Low-rank Tensor Estimation via Cubic Sketchings","type":"publication"},{"authors":["**Botao Hao**","Will Wei Sun","Yufeng Liu","Guang Cheng"],"categories":null,"content":"","date":1517447882,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517447882,"objectID":"76d7b39c1161928c27879fb79430e128","permalink":"/publication/jcgl/","publishdate":"2018-01-31T21:18:02-04:00","relpermalink":"/publication/jcgl/","section":"publication","summary":"We consider joint estimation of multiple graphical models arising from heterogeneous and high-dimensional observations. Unlike most previous approaches which assume that the cluster structure is given in advance, an appealing feature of our method is to learn cluster structure while estimating heterogeneous graphical models. This is achieved via a high dimensional version of Expectation Conditional Maximization (ECM) algorithm (Meng and Rubin, 1993). A joint graphical lasso penalty is imposed on the conditional maximization step to extract both homogeneity and heterogeneity components across all clusters. Our algorithm is computationally efficient due to fast sparse learning routines and can be implemented without unsupervised learning knowledge. The superior performance of our method is demonstrated by extensive experiments and its application to a Glioblastoma cancer dataset reveals some new insights in understanding the Glioblastoma cancer. In theory, a non-asymptotic error bound is established for the output directly from our high dimensional ECM algorithm, and it consists of two quantities: statistical error (statistical accuracy) and optimization error (computational complexity). Such a result gives a theoretical guideline in terminating our ECM iterations.","tags":[],"title":"Simultaneous Clustering and Estimation of Heterogeneous Graphical Models","type":"publication"}]